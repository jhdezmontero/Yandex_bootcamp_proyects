{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9d10df",
   "metadata": {},
   "source": [
    "# Megaline plan recommendation <a class='tocSkip' ></a>\n",
    "\n",
    "The purpose of this project is to classify the clients of the cellular telephone company **Megaline** to offer them one of the tariff plans (**Smart** or **Ultimate**) according to their consumption behavior. Such behavior takes into account the amount and number of calls made, number of messages sent and megabits (Mb) used monthly. We want to build a model that has an **accuracy of at least 75%** to classify each customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca32872",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-and-data-examination\" data-toc-modified-id=\"Load-and-data-examination-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load and data examination</a></span></li><li><span><a href=\"#Slicing-data-into-training,-validation-and-test-sets\" data-toc-modified-id=\"Slicing-data-into-training,-validation-and-test-sets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Slicing data into training, validation and test sets</a></span></li><li><span><a href=\"#Construction-and-evaluation-of-the-quality-of-different-models\" data-toc-modified-id=\"Construction-and-evaluation-of-the-quality-of-different-models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Construction and evaluation of the quality of different models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Logistic-regression\" data-toc-modified-id=\"Logistic-regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Logistic regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conclusion,-choosing-the-best-model\" data-toc-modified-id=\"Conclusion,-choosing-the-best-model-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Conclusion, choosing the best model</a></span></li></ul></li></ul></li><li><span><a href=\"#Check-the-quality-of-the-final-model-with-the-test-set\" data-toc-modified-id=\"Check-the-quality-of-the-final-model-with-the-test-set-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Check the quality of the final model with the test set</a></span></li><li><span><a href=\"#Sanity-test-of-the-final-model\" data-toc-modified-id=\"Sanity-test-of-the-final-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Sanity test of the final model</a></span></li><li><span><a href=\"#Final-conclusions\" data-toc-modified-id=\"Final-conclusions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Final conclusions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5e7ee",
   "metadata": {},
   "source": [
    "# Load and data examination\n",
    "\n",
    "The data is stored in the file `'users_behavior_upd.csv'` this data will be loaded into the DataFrame **`df`**. The DataFrame **`df`** consists of the following columns:\n",
    "\n",
    "* `calls`: number of calls\n",
    "* `minutes`: total duration of calls in minutes\n",
    "* `messages`: number of text messages\n",
    "* `mb_used`: Internet traffic used in megabits (MB)\n",
    "* `is_ultimate`: plan for the current month (Ultimate - `'1'`, Smart - `'0'`)\n",
    "\n",
    "Next, the data is loaded into **`df`**, its information and the first rows of the DataFrame are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e61278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier      # Decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression\n",
    "from sklearn.model_selection import train_test_split # Subset data for train and test\n",
    "from sklearn.metrics import accuracy_score           # Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5409ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jesusrfl/Yandex_coding_projects/phone_plan_recommendation\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   calls        3214 non-null   float64\n",
      " 1   minutes      3214 non-null   float64\n",
      " 2   messages     3214 non-null   float64\n",
      " 3   mb_used      3214 non-null   float64\n",
      " 4   is_ultimate  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultimate\n",
       "0   40.0   311.90      83.0  19915.42            0\n",
       "1   85.0   516.75      56.0  22696.96            0\n",
       "2   77.0   467.66      86.0  21060.45            0\n",
       "3  106.0   745.53      81.0   8437.39            1\n",
       "4   66.0   418.74       1.0  14502.75            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set working directory\n",
    "%cd '/Users/jesusrfl/Yandex_coding_projects/phone_plan_recommendation'\n",
    "\n",
    "# Load data into DataFrame 'df'\n",
    "df = pd.read_csv('datasets/users_behavior.csv')\n",
    "\n",
    "df.rename(columns={'is_ultra':'is_ultimate'}, inplace=True)\n",
    "\n",
    "# DataFrame info\n",
    "print(df.info())\n",
    "\n",
    "# Head df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0c56a",
   "metadata": {},
   "source": [
    "Our DataFrame **`df`** consists of 3214 rows and 5 variables described above. There are no missing values so we will go straight to creating the classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea8c5f",
   "metadata": {},
   "source": [
    "# Slicing data into training, validation and test sets\n",
    "\n",
    "The models are intended to classify customers into two categories (i.e. binary classification): **Ultimate** and **Ultra**. This classification is encoded in the `is_ultimate` column so this is our `target` variable. The other variables are the characteristics (`features`) of each client that will be used by the models to automatically classify the clients.\n",
    "\n",
    "To train, validate, and test our classification models, we are going to split the data into three sets. Because we do not have a test data set, the ratio for the training, validation, and test data will be 3:1:1, that is, 60, 20, and 20% respectively. According to the purpose of each set, the suffix of each dataset is the following:\n",
    "\n",
    "* **`_train`**: training data set which corresponds to 60% of the original data\n",
    "* **`_valid`**: validation set which corresponds to 20% of the original data\n",
    "* **`_test`**: test set which corresponds to 20% of the original data\n",
    "\n",
    "Since we require three data sets, we are going to split the original data twice. In the first section, 60% of the data is reserved for the training set. The remaining 40% of data will be divided in half (ie 20% and 20%) to originate the validation and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de177202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:   1928\n",
      "Validation set: 643\n",
      "Test set:       643\n"
     ]
    }
   ],
   "source": [
    "# Train slicing 60%\n",
    "df_train, df_valid_test = train_test_split(df, test_size = 0.4, random_state = 54321)\n",
    "\n",
    "# Data slicing ('df_valid_test') validation (20%) y test (20%)\n",
    "df_valid, df_test = train_test_split(df_valid_test, test_size = 0.5, random_state= 54321)\n",
    "\n",
    "# tamaño de cada conjunto\n",
    "print('Training set:  ', len(df_train))\n",
    "print('Validation set:', len(df_valid))\n",
    "print('Test set:      ', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040578e1",
   "metadata": {},
   "source": [
    "Once the sets have been obtained, we will proceed to select the variables to build and evaluate the models (`features`) as well as the objective variable of each set (`target`) which in this case is `is_ultimate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05ce035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of features 'features_' from each set\n",
    "features_train = df_train.drop('is_ultimate', axis=1) \n",
    "features_valid = df_valid.drop('is_ultimate', axis=1)\n",
    "features_test =  df_test.drop('is_ultimate', axis=1)\n",
    "\n",
    "# Selection of objective variable 'target' of each set\n",
    "target_train = df_train['is_ultimate']\n",
    "target_valid = df_valid['is_ultimate']\n",
    "target_test =  df_test['is_ultimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60457e13",
   "metadata": {},
   "source": [
    "Once the characteristics and objective of each data set have been defined, we proceed to build our classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344467fa",
   "metadata": {},
   "source": [
    "# Construction and evaluation of the quality of different models\n",
    "\n",
    "Since the purpose of the project is a classification task, we are going to build three classification models:\n",
    "1. [Decision Tree](#3.1)\n",
    "2. [Random Forest](#3.2)\n",
    "3. [Logistic Regression](#3.3)\n",
    "\n",
    "Once built we will select the best model according to its accuracy percentage. We will seek to optimize the decision tree and random forest models by modifying their hyperparameters. The model with the best accuracy will be trained again with the training and validation data set and will be finally evaluated with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7839d02",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "The first model we are going to build is a decision tree. This model will seek to optimize by modifying one of its hyperparameters: `max_depth` which determines how deep the decision tree is, that is, how many branches the algorithm makes to make a decision to classify each customer. The depth of the tree will be iterated with values from 1 to 10; its precision will be determined to select the tree whose depth of greatest precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52261272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model in the validation set: 0.883298755186722\n",
      "Optimum depth: 10\n"
     ]
    }
   ],
   "source": [
    "# Characteristics of the optimal model\n",
    "best_ad_model = None # Select the model with the optimal hyperparameters\n",
    "best_ad_score = 0    # Calculate the precision of the optimal model\n",
    "best_ad_depth = 0    # Indicates the optimal depth of the model\n",
    "\n",
    "# Build classification trees iterating depths from 1 to 10\n",
    "for depth in range(1, 11):  # Set the range of the max_depht hyperparameter\n",
    "    ad_model = DecisionTreeClassifier(max_depth=depth, random_state=54321) # Set max_depth\n",
    "    ad_model.fit(features_train, target_train) # Fits model to the training data\n",
    "    predictions = ad_model.predict(features_train) # Predictions\n",
    "    score = accuracy_score(target_train, predictions) # Accuracy score\n",
    "    if score > best_ad_score:\n",
    "        best_ad_model = ad_model\n",
    "        best_ad_score = score\n",
    "        best_ad_depth = depth\n",
    "\n",
    "print(\"Accuracy of the best model in the validation set:\", best_ad_score) \n",
    "print(\"Optimum depth:\", best_ad_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb65f79",
   "metadata": {},
   "source": [
    "The best-fit decision tree has a depth of 10 and offers an **88% accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d58b3",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "In this section we are going to build models by modifying the hyperparameters that determine the number of trees in the forest (`n_estimators`) and the maximum depth of each tree (`max_depth`). The `n_estimators` hyperparameter will evaluate from 10 to 100 in intervals of 10 ie (10, 20, 30, . . . 100 trees) and `max_depth` will have a range from 1 to 10.\n",
    "\n",
    "To determine the model with the appropriate hyperparameters, the accuracy of each model will be compared using the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6cd0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model in the validation set (n_estimators = 11, max_depth = 8): 0.7978227060653188\n"
     ]
    }
   ],
   "source": [
    "# Characteristics of the optimal model\n",
    "best_ba_score = 0 # Accuracy\n",
    "best_est = 0      # Number of estimators (trees)\n",
    "best_ba_depth = 0 # Optimum depth\n",
    "\n",
    "for est in range(1, 101, 10): # Select n_estimators\n",
    "    for depth in range(1,11): # Select max_depht\n",
    "        ba_model = RandomForestClassifier(random_state=54321, n_estimators=est, max_depth=depth)\n",
    "        ba_model.fit(features_train, target_train) # Model fitting\n",
    "        score = ba_model.score(features_valid, target_valid) # Accuracy over valid set\n",
    "        if score > best_ba_score:\n",
    "            best_ba_score = score # Best model according its accuracy\n",
    "            best_est = est        # Optimal number of trees\n",
    "            best_ba_depth = depth # Optimal depth\n",
    "\n",
    "print(\"Accuracy of the best model in the validation set (n_estimators = {}, max_depth = {}): {}\".format(best_est, best_ba_depth, best_ba_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c3549",
   "metadata": {},
   "source": [
    "The optimal random forest model consists of **11** decision trees (`n_estimators`) with a maximum depth of **8** (`max_depth`). This model offers **~80% accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a1c9a",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Finally we are going to build a logistic regression model. In this model we are not going to change any hyperparameter, we are only going to define the `solver` hyperparameter as `'liblinear'`. Once our model is built we will determine its precision and choose the model with the highest precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f262ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de regresión logística: 0.6780715396578538\n"
     ]
    }
   ],
   "source": [
    "# Model build\n",
    "rl_model = LogisticRegression(random_state=54321, solver='liblinear') # Define model\n",
    "rl_model.fit(features_train, target_train) # Model fit\n",
    "rl_predictions = rl_model.predict(features_valid) # Predictions\n",
    "rl_score = accuracy_score(target_valid, rl_predictions) # Accuracy \n",
    "print('Exactitud del modelo de regresión logística:', rl_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c692c10",
   "metadata": {},
   "source": [
    "### Conclusion, choosing the best model\n",
    "\n",
    "The **logistic regression model has an accuracy of ~68%** so it does not exceed the required threshold of 75%. **The random forest model had the highest accuracy score at 88%** beating the random forest model which scored 80% accurate.\n",
    "\n",
    "In the next section, we are going to check the quality of our random forest model by training it with the combined training and validation datasets and then evaluate its accuracy with the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f940056",
   "metadata": {},
   "source": [
    "# Check the quality of the final model with the test set\n",
    "\n",
    "We have already found that the decision tree model with a depth of 10 is the model that offers the highest precision; now we are going to train it again but using the combined training and validation sets to later evaluate the model using the test data set (`_test`).\n",
    "\n",
    "First, let's concatenate the training (`df_train`) and validation (`df_valid`) data into the DataFrame (`df_tv`) and get the feature (`tv_features`) and target (`tv_target`) variables. The prefix or suffix `'tv'` refers to the combined set 'train-valid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98e8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de conjunto de entrenamiento para modelo final: 2571\n"
     ]
    }
   ],
   "source": [
    "# Concatenation of training and validation sets in 'df_tv'\n",
    "df_tv = pd.concat([df_train, df_valid], axis=0)\n",
    "print('Tamaño de conjunto de entrenamiento para modelo final:', len(df_tv))\n",
    "\n",
    "# Selection of features 'features_tv'\n",
    "features_tv = df_tv.drop('is_ultimate', axis=1)\n",
    "\n",
    "# Selection of target 'target_tv'\n",
    "target_tv = df_tv['is_ultimate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ccfef",
   "metadata": {},
   "source": [
    "Now we proceed to fit the final model **`final_model`** with the combined training and validation data and check its accuracy with the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5ae72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "# Definition of the decision tree model with a depth of 10\n",
    "final_ad_model = DecisionTreeClassifier(max_depth=10, random_state=54321)\n",
    "\n",
    "# Model fitting with combined data \n",
    "final_ad_model.fit(features_tv, target_tv) \n",
    "\n",
    "# Model accuracy over test set\n",
    "print(final_ad_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099c00c",
   "metadata": {},
   "source": [
    "Our final decision tree model, re-trained with the combined training and validation set, is **80% accurate**. This accuracy percentage exceeds the 75% accuracy threshold required for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9aa07",
   "metadata": {},
   "source": [
    "# Sanity test of the final model\n",
    "\n",
    "We are going to perform a sanity test of our final decision tree model. To carry out this test, we are going to verify that the accuracy of the final model of the classification tree shows a similar accuracy with the training set and the test set.\n",
    "\n",
    "First we are going to look at the proportion of customers for each plan using our test dataset (`target_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec6ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ultimate\n",
      "0    0.724728\n",
      "1    0.275272\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How many customers are in each category (Smart - 0, Ultimate - 1)\n",
    "print(pd.DataFrame(target_test).value_counts('is_ultimate', normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba17333",
   "metadata": {},
   "source": [
    "The proportions of the categories predicted by our model are similar. We are going to analyze if the accuracy score differs between the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f574413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set: 0.8774795799299884\n",
      "Test set:     0.80248833592535\n"
     ]
    }
   ],
   "source": [
    "train_predictions = final_ad_model.predict(features_tv)\n",
    "test_predictions = final_ad_model.predict(features_test)\n",
    "\n",
    "print('Accuracy')\n",
    "print('Training set:', accuracy_score(target_tv, train_predictions))\n",
    "print('Test set:    ', accuracy_score(target_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6649c",
   "metadata": {},
   "source": [
    "Our model is better with the training set than with the test set, however it still exceeds the accuracy threshold required for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d3985",
   "metadata": {},
   "source": [
    "# Final conclusions\n",
    "\n",
    "We carry out three classification models: Decision Tree, Random Forest and Logistic Regression to automatically classify the appropriate plan for each client according to their consumption behavior. The customer data was divided into subsets to train, validate, and test each model. The model with the best precision was the Decision Tree with an accuracy over the test set of 80%, exceeding the threshold of 75% required. The proportions of customers under each category ('Smart' or 'Ultimate') predicted by our final model are similar to those observed in the test set passing the sanity test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
